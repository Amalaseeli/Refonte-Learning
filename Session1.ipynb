{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76863ca-3f37-44d7-8c4e-cc92496e1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cbffc7-a918-441a-9095-a4429d705cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ca505bd-d0c1-4a24-81a4-e806dbf4d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb=6\n",
    "head_size=1\n",
    "block_size=8\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \n",
    "    '''one head in self attention'''\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key=nn.Linear(n_emb,head_size)\n",
    "        self.query=nn.Linear(n_emb,head_size)\n",
    "        self.value=nn.Linear(n_emb,head_size)\n",
    "        \n",
    "        self.register_buffer('trill', torch.tril(torch.ones(block_size,block_size)))\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch, blocks, X = x.shape\n",
    "        key = self.key(x) # batch, block_size, X -- shape\n",
    "        query = self.query(x) # batch, block_size, X -- shape\n",
    "        weight = query @ key.transpose(-2, -1) * X ** (-0.5)\n",
    "        weight=weight.masked_fill(self.trill[:blocks, :blocks] ==0 , float('-inf'))\n",
    "        weight=F.softmax(weight, dim=-1)\n",
    "        out = weight @ self.value(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0645fe9-a715-4534-b8af-190e7b01a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Head(\n",
       "  (key): Linear(in_features=6, out_features=2, bias=True)\n",
       "  (query): Linear(in_features=6, out_features=2, bias=True)\n",
       "  (value): Linear(in_features=6, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=Head(2)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a9251e6-cff9-4b95-a542-e536d8fb1c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795]],\n",
       "\n",
       "        [[-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795]],\n",
       "\n",
       "        [[-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795],\n",
       "         [-0.1966, -0.1795]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(torch.zeros(3,8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52e58e59-8d48-4032-9cb4-60c9d3ad6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''multihead in self attention'''\n",
    "    def __init__(self, head_size, num_heads):\n",
    "        super(),__init__()\n",
    "        self.heads=nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.layer=nn.Linear(n_emb,n_emb)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=torch.cat([h(x) for h in self.head], dim=-1)\n",
    "        return self.layer(out)\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41111550-2075-4bc0-891d-d11073e8d1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
